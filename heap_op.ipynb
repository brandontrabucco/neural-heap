{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Custom Operations to Tensorflow using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to @harpone for the example\n",
    "# https://gist.github.com/harpone/3453185b41d8d985356cbe5e57d67342\n",
    "def py_func(func, inp, Tout, stateful=True, name=None, grad=None):\n",
    "    rnd_name = 'PyFuncGrad' + str(np.random.randint(0, 1e+8))\n",
    "    tf.RegisterGradient(rnd_name)(grad)\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({\"PyFunc\": rnd_name}):\n",
    "        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to @harpone for the example\n",
    "# https://gist.github.com/harpone/3453185b41d8d985356cbe5e57d67342\n",
    "def square(x, name=None):\n",
    "    with ops.name_scope(name, \"MySquareFunc\", [x]) as name:\n",
    "        sqr_x = py_func(np.square,\n",
    "            [x],\n",
    "            [tf.float32],\n",
    "            name=name,\n",
    "            grad=square_grad)\n",
    "        return sqr_x[0]\n",
    "def square_grad(op, grad):\n",
    "    x = op.inputs[0]\n",
    "    return grad * 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.] [1. 4.] [2. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Credit to @harpone for the example\n",
    "# https://gist.github.com/harpone/3453185b41d8d985356cbe5e57d67342\n",
    "with tf.Session() as sess:\n",
    "    x = tf.constant([1., 2.])\n",
    "    y = square(x)\n",
    "    print(x.eval(), y.eval(), tf.gradients(y, x)[0].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Heap using Custom Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFMinHeapPQ(object):\n",
    "    \"\"\"This clas enables a min heap priority queue \n",
    "    data structure to interface with tensorflow \n",
    "    computational graphs.\"\"\"\n",
    "    \n",
    "    class Node(object):\n",
    "        \"\"\"This class is used as a container for vectors\n",
    "        that can be compared using a hashing function.\"\"\"\n",
    "        def __init__(self, x, outer):\n",
    "            self.x = x\n",
    "            self.outer = outer\n",
    "        def __eq__(self, y):\n",
    "            return self.outer.h(self.x) == y.outer.h(y.x)\n",
    "        def __ne__(self, y):\n",
    "            return self.outer.h(self.x) != y.outer.h(y.x)\n",
    "        def __gt__(self, y):\n",
    "            return self.outer.h(self.x) > y.outer.h(y.x)\n",
    "        def __lt__(self, y):\n",
    "            return self.outer.h(self.x) < y.outer.h(y.x)\n",
    "        def __ge__(self, y):\n",
    "            return self.outer.h(self.x) >= y.outer.h(y.x)\n",
    "        def __le__(self, y):\n",
    "            return self.outer.h(self.x) <= y.outer.h(y.x)\n",
    "    \n",
    "    def __init__(self, n, i, v, h):\n",
    "        \"\"\"Initialize the data structure with a name \n",
    "        for the operation, the number of instances of the \n",
    "        data structure, the size of element vectors, \n",
    "        and the hashing function.\"\"\"\n",
    "        self.name = n\n",
    "        self.instances = i\n",
    "        self.vsize = v\n",
    "        self.pq = [[] for _ in range(i)]\n",
    "        self.h = h\n",
    "        \n",
    "    def _interact(self, operator, operand):\n",
    "        \"\"\"Given a vector of action probabilities, \n",
    "        and a vector argument, interact with the \n",
    "        priority queue.\n",
    "        operator: shape ([...=instances], 3) numpy array.\n",
    "        operand: shape ([...=instances], vsize) numpy array.\n",
    "        returns: numpy array same shape as operand.\"\"\"\n",
    "        operator = operator.reshape(\n",
    "            (self.instances, 3))\n",
    "        operand = operand.reshape(\n",
    "            (self.instances, self.vsize))\n",
    "        action = np.argmax(operator, axis=-1)\n",
    "        result = []\n",
    "        for i in range(self.instances):\n",
    "            if action[i] == 0:\n",
    "                heappush(\n",
    "                    self.pq[i], \n",
    "                    TFMinHeapPQ.Node(\n",
    "                        operand[i, :], \n",
    "                        self))\n",
    "                result += [operand[i, :]]\n",
    "            elif action[i] == 1:\n",
    "                result += [self.pq[i][0].x]\n",
    "            else:\n",
    "                result += [heappop(self.pq[i]).x]\n",
    "        return np.vstack(result)\n",
    "    \n",
    "    def _interact_grad(self, op, grad):\n",
    "        \"\"\"Currently this op is not differentiable, \n",
    "        and so gradients are zero.\"\"\"\n",
    "        operator = op.inputs[0]\n",
    "        operand = op.inputs[1]\n",
    "        return grad * 0, grad * 0\n",
    "    \n",
    "    def interact(self, operator, operand):\n",
    "        \"\"\"Connect the data structure to delayed computation, \n",
    "        as part of a computational graph.\"\"\"\n",
    "        with ops.name_scope(\n",
    "                self.name,\n",
    "                self.name,\n",
    "                [operator, operand]) as name:\n",
    "            result = py_func(\n",
    "                self._interact,\n",
    "                [operator, operand],\n",
    "                [tf.float32],\n",
    "                name=name,\n",
    "                grad=self._interact_grad)\n",
    "            return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n",
      "[[1. 2.]]\n",
      "[[1. 2.]]\n",
      "[[0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    operator = tf.constant([[1., 0., 0.]])\n",
    "    operand = tf.constant([[1., 2.]])\n",
    "    tf_pq = TFMinHeapPQ(\"MinHeap\", 1, 2, lambda x: np.sum(x))\n",
    "    y = tf_pq.interact(operator, operand)\n",
    "    \n",
    "    print(operator.eval())\n",
    "    print(operand.eval())\n",
    "    print(y.eval())\n",
    "    print(tf.gradients(y, [operator, operand])[0].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
